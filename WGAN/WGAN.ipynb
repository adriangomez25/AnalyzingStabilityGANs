{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels =32, kernel_size= 4, stride = 2, padding = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels =64, kernel_size= 4, stride = 2, padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size= 4, stride = 2, padding = 1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size= 4, stride = 2, padding = 1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=1, kernel_size= 4, stride = 2, padding = 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        num_images = x.shape[0]\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)),negative_slope=0.2)\n",
    "        x =  F.leaky_relu(self.bn2(self.conv2(x)),negative_slope=0.2)\n",
    "        x =  F.leaky_relu(self.bn3(self.conv3(x)),negative_slope=0.2)\n",
    "        x =  F.leaky_relu(self.bn4(self.conv4(x)),negative_slope=0.2)\n",
    "        x = self.conv5(x)\n",
    "        return x.reshape(num_images,1)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "  #100 dimensional uniform distribution Z is input from Figure 1 of the paper\n",
    "  #First layer should have depth 1024. 1024/32 = 32\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.upscale1 = nn.ConvTranspose2d(in_channels=100, out_channels=1024,kernel_size=4,stride = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(1024)\n",
    "        self.upscale2 = nn.ConvTranspose2d(in_channels=1024, out_channels=512,kernel_size=4,stride = 2,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(512)\n",
    "        self.upscale3 = nn.ConvTranspose2d(in_channels=512, out_channels=256,kernel_size=4,stride = 2,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.upscale4 = nn.ConvTranspose2d(in_channels=256, out_channels=3,kernel_size=4,stride = 2,padding=1)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.bn1(self.upscale1(x)))\n",
    "        x = F.relu(self.bn2(self.upscale2(x)))\n",
    "        x = F.relu(self.bn3(self.upscale3(x)))\n",
    "        x = torch.tanh(self.upscale4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chanels = 3 #num channels (RBG)\n",
    "num_images =26\n",
    "dim = 32 #dim of CIFAR10 dataset = 32x32 images\n",
    "rand_image = torch.randn(num_images,num_chanels,dim,dim)\n",
    "net = Discriminator()\n",
    "out = net(rand_image)\n",
    "#Checks to see if output are correct shape\n",
    "print(list(out.shape))\n",
    "if (list(out.shape) == [num_images,1]):\n",
    "    print(\"The output is of correct shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chanels = 100 #num channels (RBG)\n",
    "num_images =10\n",
    "dim = 1 #dim of CIFAR10 dataset = 32x32 images\n",
    "rand_image = torch.randn(num_images,num_chanels,dim,dim)\n",
    "net = Generator()\n",
    "out = net(rand_image)\n",
    "#Checks to see if output are correct shape\n",
    "print(list(out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().cuda()\n",
    "for layer in discriminator.modules():\n",
    "      if isinstance(layer,nn.Conv2d):\n",
    "        nn.init.normal_(layer.weight.data,0,0.02)\n",
    "\n",
    "generator = Generator().cuda()\n",
    "for layer in discriminator.modules():\n",
    "      if isinstance(layer,nn.ConvTranspose2d):\n",
    "        nn.init.normal_(layer.weight.data,0,0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image_norm(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = torch.randn(n_row, 100, 1, 1).cuda()\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = torch.as_tensor(torch.LongTensor(labels))\n",
    "    #can turn off gradient computation to run\n",
    "    with torch.no_grad():\n",
    "        gen_imgs = generator(z)\n",
    "    save_image(gen_imgs.data, \"DC_GAN_images_norm/%d.png\" % batches_done, normalize=True)\n",
    "\n",
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = torch.randn(n_row, 100, 1, 1).cuda()\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = torch.as_tensor(torch.LongTensor(labels))\n",
    "    #can turn off gradient computation to run\n",
    "    with torch.no_grad():\n",
    "        gen_imgs = generator(z)\n",
    "    #set normalization to False\n",
    "    save_image(gen_imgs.data, \"DC_GAN_images/%d.png\" % batches_done, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"WGAN_images\", exist_ok=True)\n",
    "os.makedirs(\"WGAN_images_norm\", exist_ok=True)\n",
    "os.makedirs(\"WGAN_data\", exist_ok=True)\n",
    "os.makedirs(\"WGAN_model\", exist_ok=True)\n",
    "os.makedirs(\"WGAN_GEN_WEIGHTS\", exist_ok=True)\n",
    "os.makedirs(\"WGAN_GEN_GRADS\", exist_ok=True)\n",
    "os.makedirs(\"WGAN_DISC_GRADS\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set hyperparameters and Normalization\n",
    "sample_interval=391\n",
    "NUM_EPOCHS = 200\n",
    "\n",
    "sample_interval=391\n",
    "NUM_EPOCHS = 200\n",
    "alpha = 5e-5\n",
    "batch_size = 64\n",
    "n_critic=5\n",
    "c = 0.01\n",
    "\n",
    "optimizer_gen= optim.RMSprop(generator.parameters(), lr=alpha)\n",
    "optimizer_disc = optim.RMSprop(discriminator.parameters(), lr=alpha)\n",
    "transform = transforms.Compose([transforms.Resize(32), transforms.ToTensor()])\n",
    "\n",
    "dataset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_g_list=[]\n",
    "loss_d_list=[]\n",
    "\n",
    "#set models to train \n",
    "generator.train()\n",
    "discriminator.train()\n",
    "print(\"Ready to Run!\")\n",
    "\n",
    "#run loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    grad_dict = collections.defaultdict(list)\n",
    "    #torch.save(generator,\"DC_GAN_GEN_WEIGHTS/weights\" + str(epoch) + \".pt\")\n",
    "    #torch.save(optimizer_gen.state_dict(), \"DC_GAN_GEN_GRADS/GradientsGen\" + str(epoch) + \".pt\")\n",
    "    #torch.save(optimizer_disc.state_dict(), \"DC_GAN_DISC_GRADS/GradientsDisc\" + str(epoch) + \".pt\")\n",
    "\n",
    "\n",
    "    for batch_idx, (real, _) in enumerate(dataloader):\n",
    "        real = real.cuda() #get real images\n",
    "\n",
    "        for k in range(n_critic):\n",
    "            ### Train Discriminator\n",
    "            \n",
    "            noise = torch.randn(m, 100, 1, 1).cuda()\n",
    "            fake = generator(noise)\n",
    "            disc_real = discriminator(real).reshape(-1)\n",
    "            disc_fake = discriminator(fake).reshape(-1)\n",
    "            loss_disc= -(torch.mean(disc_real) - torch.mean(disc_fake))\n",
    "            discriminator.zero_grad() #zero gradients \n",
    "            loss_disc.backward(retain_graph=True) #backpropagation\n",
    "            optimizer_disc.step()\n",
    "        \n",
    "            for params in discriminator.parameters():\n",
    "                params.data.clamp_(-c, c)\n",
    "\n",
    "        ### Train Generator\n",
    "        output = discriminator(fake).reshape(-1) #have discriminator classify fake \n",
    "        loss_gen = -torch.mean(output)\n",
    "        generator.zero_grad() #zero gradients \n",
    "        loss_gen.backward() #backpropagation\n",
    "        optimizer_gen.step()\n",
    "        \n",
    "\n",
    "        #below jsut saves some data \n",
    "        batches_done = epoch * len(dataloader) + batch_idx\n",
    "        if batches_done % sample_interval == 0:\n",
    "            sample_image_norm(n_row=64, batches_done=batches_done)\n",
    "            sample_image(n_row=64, batches_done=batches_done)\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            #'model_state_dict': generator.state_dict(),\n",
    "            #'optimizer_state_dict': optimizer_gen.state_dict(),\n",
    "            'loss_gen': loss_gen,\n",
    "            'loss_disc': loss_disc,\n",
    "            }, \"./DC_GAN_model/model\"+str(epoch)+\".pth\")\n",
    "    \n",
    "    #add loss to lists for later plotting\n",
    "    loss_g_list.append(loss_gen)\n",
    "    loss_d_list.append(loss_disc)\n",
    "    \n",
    "    for layer in discriminator.modules():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            grad = layer.weight.grad.cpu().numpy()\n",
    "            num_weights = (np.abs(grad) < 0.1).sum()\n",
    "            mean = np.mean(grad)\n",
    "            std = np.std(grad)\n",
    "            val = [mean,std,num_weights]\n",
    "            grad_dict[epoch].append(val)\n",
    "            \n",
    "    with open('grad_dict' + str(epoch) + '.pkl', 'wb') as f:\n",
    "        pickle.dump(grad_dict, f)\n",
    "        \n",
    "    #print what epoch we are on \n",
    "    print(\n",
    "          \"[Epoch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "           % (epoch, NUM_EPOCHS, loss_disc.item(), loss_gen.item())\n",
    "          )\n",
    "    generator.train()\n",
    "    discriminator.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
